{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "import re\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_sample(sample):\n",
    "    try:\n",
    "        if sample[-2:] == '. ':\n",
    "            new_sample = sample\n",
    "\n",
    "        elif sample[-1] == '.':\n",
    "            new_sample = sample+' '\n",
    "\n",
    "        elif sample[-1] != '.':\n",
    "            new_sample = sample+'. '\n",
    "\n",
    "        else:\n",
    "            print('please check the data!')\n",
    "    except:\n",
    "        new_sample = sample\n",
    "        \n",
    "    return new_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_sent(text:str)->list:\n",
    "    # split 시 무시할 패턴 정의  \n",
    "    # 숫자. 로 끝나는 경우 \n",
    "    check = \"\"\"(eqs?\\.)|(figs?\\.)|(sect\\.)|\\     # eq.(eqs.), fig.(figs.), sec.(SEC.),\n",
    "    (sec\\.)|(et\\.)|(\\s?al\\.)|(\\s?et\\.?\\sal\\.)|\\  #  et. al. \n",
    "    (S?\\.?\\s?\\d*ff\\.)$|(dvbl\\.)|(vgl\\.)|\\        # 추가: '.857ff.','3) Vgl.'  11.18\n",
    "    ^(e\\.)|(\\s?\\(?[A-Z]{1,4}\\.)|^([A-Z]\\.)|\\     # 시작 시 e. g. (S. S. 로 시작할 경우, ABCD. 와 같은 경우 추가(+11.18)\n",
    "    ([가-힣]{1,2}\\s\\.)$|\\                         # 다. 일경우만 제외하는 등 변경 필요\n",
    "    (\\(?e\\.\\s?g\\.)|(\\(?i\\.\\s?e\\.)|\\\n",
    "    ([MDCLXVI]{1,2}\\.)$\\                         # 로마자 추가\n",
    "    |(dix.)\\\n",
    "    |(no\\.)|([0-9]\\.)$|(vs\\.)|(ref\\.)|(cf\\.)\\    # no. 1. vs. ref.(Ref.) cf.(Cf.)\n",
    "    \"\"\"\n",
    "    pp = re.compile(check, re.VERBOSE|re.IGNORECASE)\n",
    "    na_count = 0\n",
    "\n",
    "        \n",
    "    # 예외처리: 문장 끝에 .(공백없음)으로 끝나거나 .이 없는 경우\n",
    "    sample = new_sample(text)\n",
    "    splited_list = []\n",
    "    prev_end = 0\n",
    "    \n",
    "    try:\n",
    "        # .으로 끝나는 모든 경우를 find\n",
    "        for sent in re.finditer('(\\.\\s)', sample):\n",
    "            start = sent.span()[0]\n",
    "            end = sent.span()[1]\n",
    "\n",
    "            if start < 6:\n",
    "                token = sample[start-start:end-1]\n",
    "            else:\n",
    "                token = sample[start-6:end-1]\n",
    "\n",
    "    #         print()\n",
    "    #         print(pp.search(token))\n",
    "    #         print(token)\n",
    "    #         print(prev_end, end)\n",
    "    #         print(len(sample))\n",
    "\n",
    "            # '. ' 앞뒤에 check에 해당하는 패턴이 없는 경우 문장으로 나누기\n",
    "            if (pp.search(token) == None):\n",
    "                if re.search('(\\s\\(?\\w\\.\\)?)$', token) == None:  # 위의 check에서 제대로 동작 안 해서 따로 집어 넣음\n",
    "                    splited_list.append(sample[prev_end:end-1])\n",
    "                    prev_end = end\n",
    "\n",
    "            elif pp.search(token) != None:\n",
    "                if len(sample) == end:\n",
    "                    splited_list.append(sample[prev_end:end-1])\n",
    "                    \n",
    "    except:\n",
    "        print(f'error occured!')\n",
    "        print(sample)\n",
    "    return splited_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05a6b653f98442a49dc11e2b4518870f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result_1092_금전거래와법_거래를통해배우는민법1(정성헌)_한양.txt\n",
      "result_LB0026_경제법[제8판]_한양.txt\n",
      "result_LP0037_대기업집단 규제론_한양.txt\n",
      "result_LP0077_Global_Labour_and_Employment_Relations(김동원)_한양.txt\n",
      "result_LP0095_2000년대민사판례의경향과흐름[우수학술도서 선정](민사판례연구회)_한양.txt\n",
      "result_LP0752_민사판례연구(32)(민사판례연구회 편)_1_한양.txt\n",
      "result_LP0753_민사판례연구(33-상)(민사판례연구회 편)_1_한양.txt\n",
      "result_LP0754_민사판례연구(33-하)(민사판례연구회 편)_1_한양.txt\n",
      "result_LP0756_민사판례연구(35)(민사판례연구회 편)_1_한양.txt\n",
      "result_LP0757_민사판례연구(36)(민사판례연구회 편)_1_한양.txt\n",
      "result_LP0779_행정판례연구XXVI-1(행정판례연구회 편)_1_한양.txt\n",
      "result_LP0790_행정판례연구15-2_1_한양.txt\n",
      "result_LP0794_행정판례연구XXV-1(행정판례연구회)_1_한양.txt\n",
      "result_LP0796_행정판례연구XIX-1(한국행정판례연구회 편)_1_한양.txt\n",
      "result_LP0797_행정판례연구XIX-2(한국행정판례연구회 편) (1)_1_한양.txt\n",
      "result_LP0801_행정판례연구 18-2_1_한양.txt\n",
      "result_LP0804_행정판례연구21-1_1_한양.txt\n",
      "result_LP0805_행정판례연구21-2_1_한양.txt\n",
      "result_LP0809_행정판례연구23-1_1_한양.txt\n",
      "result_LP0811_행정판례연구24-2_1_한양.txt\n",
      "result_LP0869.경찰행정법_한양.txt\n",
      "result_LP0876.기본경찰행정법_한양.txt\n",
      "result_LP0886.신행정법입문(홍정선)_한양.txt\n",
      "result_LP1025_탐정과형법(1)(강동욱)_한양.txt\n",
      "result_LP1111_부동산유치권강의(이찬양)_한양.txt\n",
      "result_LP1113_부동산거래와법(정성헌)_한양.txt\n",
      "result_LP328_성폭력범죄법률가이드(제2판)(김형규)_한양.txt\n"
     ]
    }
   ],
   "source": [
    "path_1 = r\"C:\\Users\\Samsung\\jupyter\\Project_Medical_Legal\\data\\20230104\\hanyang\\00 변환\"\n",
    "reg = re.compile(r\"result\\.([a-zA-Z0-9_]+)\\.\")\n",
    "\n",
    "os.chdir(path_1)\n",
    "tq = tqdm(os.listdir())\n",
    "fn_list = []\n",
    "for i in tq:\n",
    "    print(i)\n",
    "    if i.endswith(\".txt\"):\n",
    "        fn_ = reg.findall(i.replace(\"_\",\".\"))[0]\n",
    "        fn_ = \"result_\" + fn_\n",
    "        #print(fn_)\n",
    "        fn_list.append(fn_)\n",
    "        #print(fn_)\n",
    "        f = open(path_1+\"\\\\\"+i, 'rt',encoding=\"utf-8\")\n",
    "        globals ()[\"{}\".format(fn_)] = \"\"\n",
    "        line = f.read()\n",
    "        globals ()[\"{}\".format(fn_)] = globals ()[\"{}\".format(fn_)] + line\n",
    "         #print(line)\n",
    "        f.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = r\"C:\\Users\\Samsung\\jupyter\\Project_Medical_Legal\\data\\20230104\\hanyang\\result\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_chapter(origi_,reg):\n",
    "    spli_ = []\n",
    "    for i in reg.finditer(origi_):\n",
    "        spli_.append([i.group(),i.span()])\n",
    "    return spli_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_chapter(origi_):\n",
    "    reg = re.compile(\"\\[\\[CHAPTER\\]\\] +(\\w+) +\\[\\[BODY\\]\\] +(\\w+)-?(\\w+)?\")\n",
    "    spli_ = find_chapter(origi_,reg)\n",
    "    if spli_ != []:\n",
    "        pass\n",
    "    elif spli_ == []:\n",
    "        reg = re.compile(\"CHAPTER\")\n",
    "        spli_ = find_chapter(origi_,reg)\n",
    "    if spli_ != []:\n",
    "        data_all = []\n",
    "        for i in range(len(spli_)):\n",
    "            chap = spli_[i][0]\n",
    "            try:\n",
    "                star_ = spli_[i][1][1]\n",
    "                end_ = spli_[i+1][1][0]\n",
    "                data_ = origi_[star_:end_].split(\"  \")\n",
    "            except:\n",
    "                star_ = spli_[i][1][1]\n",
    "                data_ = origi_[star_:].split(\"  \")\n",
    "            data_all.append([chap,data_])\n",
    "    else:\n",
    "        data_all = []\n",
    "    return data_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
